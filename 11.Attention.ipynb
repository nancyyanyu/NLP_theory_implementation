{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, GRU, Dense, Embedding, Bidirectional, RepeatVector, Concatenate, Dot, Lambda\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 20000\n"
     ]
    }
   ],
   "source": [
    "# some config\n",
    "BATCH_SIZE = 64  # Batch size for training.\n",
    "EPOCHS = 30  # Number of epochs to train for.\n",
    "LATENT_DIM = 400  # Latent dimensionality of the encoding space.\n",
    "NUM_SAMPLES = 20000  # Number of samples to train on.\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "# idea: make it different to ensure things all fit together properly!\n",
    "LATENT_DIM_DECODER = 400\n",
    "\n",
    "input_texts = []  # sentence in original language\n",
    "target_texts = []  # sentence in target language\n",
    "target_texts_inputs = []  # sentence in target language offset by 1\n",
    "\n",
    "# load in the data\n",
    "t = 0\n",
    "for line in open(\"./large_files/spa.txt\"):\n",
    "    t += 1\n",
    "    if t > NUM_SAMPLES:\n",
    "        break\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "    input_text, translation, *rest = line.rstrip().split('\\t')\n",
    "    target_text = translation+' <eos>'\n",
    "    target_text_input = '<sos> '+translation\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    target_texts_inputs.append(target_text_input)\n",
    "print(\"num samples:\", len(input_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3768 unique input tokens.\n",
      "Found 10503 unique input tokens.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the inputs\n",
    "\n",
    "# tokenize the inputs\n",
    "tokenizer_input = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_input.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_input.texts_to_sequences(input_texts)\n",
    "\n",
    "# explanation:\n",
    "# input_texts - english sentences\n",
    "# input_sequences - vectors of integers\n",
    "len(input_sequences), len(input_texts)\n",
    "\n",
    "# get the word to index mapping for input language\n",
    "word2idx_input = tokenizer_input.word_index\n",
    "print('Found %s unique input tokens.' % len(word2idx_input))\n",
    "\n",
    "# determine maximum length input sequence\n",
    "max_input_length = max(len(s) for s in input_sequences)\n",
    "max_input_length\n",
    "\n",
    "# Tokenize the outputs\n",
    "\n",
    "# tokenize the outputs\n",
    "# don't filter out special characters\n",
    "# otherwise <sos> and <eos> won't appear\n",
    "tokenizer_target = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "tokenizer_target.fit_on_texts(target_texts+target_texts_inputs)\n",
    "target_sequences = tokenizer_target.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_target.texts_to_sequences(\n",
    "    target_texts_inputs)\n",
    "\n",
    "# get the word to index mapping for output language\n",
    "word2idx_target = tokenizer_target.word_index\n",
    "print('Found %s unique input tokens.' % len(word2idx_target))\n",
    "\n",
    "# store number of output words for later\n",
    "# remember to add 1 since indexing starts at 1\n",
    "num_words_target = len(word2idx_target)+1\n",
    "\n",
    "# determine maximum length output sequence\n",
    "max_target_length = max(len(s) for s in target_sequences)\n",
    "max_target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_inputs.shape: (20000, 6)\n",
      "encoder_inputs[0]: [ 0  0  0  0  0 22]\n",
      "decoder_inputs[0]: [   2 2846    0    0    0    0    0    0    0    0    0    0    0]\n",
      "decoder_inputs.shape: (20000, 13)\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# pad the sequences\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_input_length)\n",
    "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
    "print(\"encoder_inputs[0]:\", encoder_inputs[0])\n",
    "decoder_inputs = pad_sequences(\n",
    "    target_sequences_inputs, maxlen=max_target_length, padding='post')\n",
    "print(\"decoder_inputs[0]:\", decoder_inputs[0])\n",
    "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
    "decoder_targets = pad_sequences(\n",
    "    target_sequences, maxlen=max_target_length, padding='post')\n",
    "\n",
    "# Load pre-trained word vectors\n",
    "\n",
    "# load in pre-trained word vectors\n",
    "word2vec = {}\n",
    "with open('./large_files/glove.6B/glove.6B.{}d.txt'.format(EMBEDDING_DIM)) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.array(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))\n",
    "\n",
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_input)+1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_input.items():\n",
    "    if i < MAX_NUM_WORDS:\n",
    "        embedding_vec = word2vec.get(word)\n",
    "        if embedding_vec is not None:\n",
    "            embedding_matrix[i] = embedding_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding layer\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_input_length)\n",
    "\n",
    "# create targets, since we cannot use sparse\n",
    "# categorical cross entropy when we have sequences\n",
    "\n",
    "# one-hot the targets (can't use sparse cross-entropy)\n",
    "decoder_targets_one_hot = np.zeros(\n",
    "    (len(target_sequences), max_target_length, num_words_target))\n",
    "for i, d in enumerate(decoder_targets):\n",
    "    for t, word in enumerate(d):\n",
    "        if word != 0:\n",
    "            decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the encoder\n",
    "encoder_input_placeholder=Input(shape = (max_input_length,))\n",
    "x=embedding_layer(encoder_input_placeholder)\n",
    "encoder = Bidirectional(LSTM(LATENT_DIM,return_sequences=True))\n",
    "encoder_outputs= encoder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention \n",
    "\n",
    "remember we need to calculate the **context vector** several times, which means we should put it into a function but we want that function to use the same weights each time, which means we should make these layers global so that we can keep reusing the same layers within the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we do softmax over the time axis\n",
    "# expected shape is N x T x D\n",
    "# note: the latest version of Keras allows you to pass in axis arg\n",
    "def softmax_over_time(x):\n",
    "    assert(K.ndim(x) > 2)\n",
    "    e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
    "    s = K.sum(e, axis=1, keepdims=True)\n",
    "    return e / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention layers need to be global because\n",
    "# they will be repeated Ty times at the decoder\n",
    "attn_repeat_layer = RepeatVector(max_input_length)\n",
    "attn_concat_layer = Concatenate(axis=-1)\n",
    "attn_dense1 = Dense(10, activation='tanh')\n",
    "attn_dense2 = Dense(1, activation=softmax_over_time)\n",
    "attn_dot = Dot(axes=1)  # to perform the weighted sum of alpha[t] * h[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(h, st_1):\n",
    "    # h = h(1), ..., h(Tx), shape = (Tx, LATENT_DIM * 2)\n",
    "    # st_1 = s(t-1), shape = (LATENT_DIM_DECODER,)\n",
    "\n",
    "    # copy s(t-1) Tx times\n",
    "    # now shape = (Tx, LATENT_DIM_DECODER)\n",
    "    st_1 = attn_repeat_layer(st_1)\n",
    "\n",
    "    # Concatenate all h(t)'s with s(t-1)\n",
    "    # Now of shape (Tx, LATENT_DIM_DECODER + LATENT_DIM * 2)\n",
    "    x = attn_concat_layer([h, st_1])\n",
    "\n",
    "    x = attn_dense1(x)\n",
    "    alpha = attn_dense2(x)\n",
    "\n",
    "    context = attn_dot([alpha, h])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder \n",
    "# create targets input which are the teacher forcing inputs.\n",
    "decoder_input_placeholder = Input(shape = (max_target_length,))\n",
    "\n",
    "# pass it into its own embedding layer\n",
    "decoder_embdding=Embedding(num_words_target,EMBEDDING_DIM)\n",
    "decoder_inputs_x = decoder_embdding(decoder_input_placeholder)\n",
    "\n",
    "# define the rest of the decoder (after attention)\n",
    "decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
    "decoder_dense = Dense(num_words_target, activation='softmax')\n",
    "\n",
    "# more inputs  - initial hidden state and cell state for LSTM\n",
    "initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n",
    "initial_c = Input(shape=(LATENT_DIM_DECODER,), name='c0')\n",
    "# another concat layer for Teacher Forcing\n",
    "# this is to combine the previous correct word with context\n",
    "context_last_word_concat_layer = Concatenate(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlike previous seq2seq, we cannot get the output\n",
    "# all in one step\n",
    "# Instead we need to do Ty steps\n",
    "# And in each of those steps, we need to consider\n",
    "# all Tx h's\n",
    "\n",
    "# s, c will be re-assigned in each iteration of the loop\n",
    "s, c = initial_s, initial_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "# loop through each output timestamp\n",
    "for t in range(max_target_length):\n",
    "\n",
    "    #  get the context using attention\n",
    "    context = one_step_attention(encoder_outputs, s)\n",
    "\n",
    "    # we need a different layer for each time step\n",
    "    # select the correct slice from its tensor as we only want the previous correct word\n",
    "    # Of course that's just whatever it is at the index t.\n",
    "    selector = Lambda(lambda x: x[:, t:t+1])\n",
    "    xt = selector(decoder_inputs_x)\n",
    "\n",
    "    # combine\n",
    "    decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
    "\n",
    "    # pass the combined [context, last word] into the LSTM\n",
    "    # along with [s, c]\n",
    "    # get the new [s, c] and output\n",
    "    o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
    "\n",
    "    # final dense layer to get next word prediction\n",
    "    decoder_output = decoder_dense(o)\n",
    "    outputs.append(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'outputs' is now a list of length Ty\n",
    "# each element is of shape (batch size, output vocab size)\n",
    "# therefore if we simply stack all the outputs into 1 tensor\n",
    "# it would be of shape T x N x D\n",
    "# we would like it to be of shape N x T x D\n",
    "def stack_transpose(x):\n",
    "    x = K.stack(x)  # is now T x batch_size x output_vocab_size tensor\n",
    "    # is now batch_size x T x output_vocab_size\n",
    "    x = K.permute_dimensions(x, pattern=(1, 0, 2))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacker = Lambda(stack_transpose)\n",
    "outputs = stacker(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    [encoder_input_placeholder, decoder_input_placeholder,initial_s, \n",
    "    initial_c,],\n",
    "    outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "  # both are of shape N x T x K\n",
    "  mask = K.cast(y_true > 0, dtype='float32')\n",
    "  out = mask * y_true * K.log(y_pred)\n",
    "  return -K.sum(out) / K.sum(mask)\n",
    "\n",
    "\n",
    "def acc(y_true, y_pred):\n",
    "  # both are of shape N x T x K\n",
    "  targ = K.argmax(y_true, axis=-1)\n",
    "  pred = K.argmax(y_pred, axis=-1)\n",
    "  correct = K.cast(K.equal(targ, pred), dtype='float32')\n",
    "\n",
    "  # 0 is padding, don't include those\n",
    "  mask = K.cast(K.greater(targ, 0), dtype='float32')\n",
    "  n_correct = K.sum(mask * correct)\n",
    "  n_total = K.sum(mask)\n",
    "  return n_correct / n_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss=custom_loss,optimizer='adam',metrics=[acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 6, 100)       376900      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 [(None, 400)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 6, 800)       1603200     embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 6, 400)       0           s0[0][0]                         \n",
      "                                                                 lstm_4[0][1]                     \n",
      "                                                                 lstm_4[1][1]                     \n",
      "                                                                 lstm_4[2][1]                     \n",
      "                                                                 lstm_4[3][1]                     \n",
      "                                                                 lstm_4[4][1]                     \n",
      "                                                                 lstm_4[5][1]                     \n",
      "                                                                 lstm_4[6][1]                     \n",
      "                                                                 lstm_4[7][1]                     \n",
      "                                                                 lstm_4[8][1]                     \n",
      "                                                                 lstm_4[9][1]                     \n",
      "                                                                 lstm_4[10][1]                    \n",
      "                                                                 lstm_4[11][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 6, 1200)      0           bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[0][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[1][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[2][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[3][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[4][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[5][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[6][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[7][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[8][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[9][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[10][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[11][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[12][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 6, 10)        12010       concatenate_4[0][0]              \n",
      "                                                                 concatenate_4[1][0]              \n",
      "                                                                 concatenate_4[2][0]              \n",
      "                                                                 concatenate_4[3][0]              \n",
      "                                                                 concatenate_4[4][0]              \n",
      "                                                                 concatenate_4[5][0]              \n",
      "                                                                 concatenate_4[6][0]              \n",
      "                                                                 concatenate_4[7][0]              \n",
      "                                                                 concatenate_4[8][0]              \n",
      "                                                                 concatenate_4[9][0]              \n",
      "                                                                 concatenate_4[10][0]             \n",
      "                                                                 concatenate_4[11][0]             \n",
      "                                                                 concatenate_4[12][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 6, 1)         11          dense_6[0][0]                    \n",
      "                                                                 dense_6[1][0]                    \n",
      "                                                                 dense_6[2][0]                    \n",
      "                                                                 dense_6[3][0]                    \n",
      "                                                                 dense_6[4][0]                    \n",
      "                                                                 dense_6[5][0]                    \n",
      "                                                                 dense_6[6][0]                    \n",
      "                                                                 dense_6[7][0]                    \n",
      "                                                                 dense_6[8][0]                    \n",
      "                                                                 dense_6[9][0]                    \n",
      "                                                                 dense_6[10][0]                   \n",
      "                                                                 dense_6[11][0]                   \n",
      "                                                                 dense_6[12][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 13, 100)      1050400     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 1, 800)       0           dense_7[0][0]                    \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 dense_7[1][0]                    \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 dense_7[2][0]                    \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 dense_7[3][0]                    \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 dense_7[4][0]                    \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 dense_7[5][0]                    \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 dense_7[6][0]                    \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 dense_7[7][0]                    \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 dense_7[8][0]                    \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 dense_7[9][0]                    \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 dense_7[10][0]                   \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 dense_7[11][0]                   \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 dense_7[12][0]                   \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1, 100)       0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1, 900)       0           dot_2[0][0]                      \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 dot_2[1][0]                      \n",
      "                                                                 lambda_15[0][0]                  \n",
      "                                                                 dot_2[2][0]                      \n",
      "                                                                 lambda_16[0][0]                  \n",
      "                                                                 dot_2[3][0]                      \n",
      "                                                                 lambda_17[0][0]                  \n",
      "                                                                 dot_2[4][0]                      \n",
      "                                                                 lambda_18[0][0]                  \n",
      "                                                                 dot_2[5][0]                      \n",
      "                                                                 lambda_19[0][0]                  \n",
      "                                                                 dot_2[6][0]                      \n",
      "                                                                 lambda_20[0][0]                  \n",
      "                                                                 dot_2[7][0]                      \n",
      "                                                                 lambda_21[0][0]                  \n",
      "                                                                 dot_2[8][0]                      \n",
      "                                                                 lambda_22[0][0]                  \n",
      "                                                                 dot_2[9][0]                      \n",
      "                                                                 lambda_23[0][0]                  \n",
      "                                                                 dot_2[10][0]                     \n",
      "                                                                 lambda_24[0][0]                  \n",
      "                                                                 dot_2[11][0]                     \n",
      "                                                                 lambda_25[0][0]                  \n",
      "                                                                 dot_2[12][0]                     \n",
      "                                                                 lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 [(None, 400)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 400), (None, 2081600     concatenate_5[0][0]              \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 concatenate_5[1][0]              \n",
      "                                                                 lstm_4[0][1]                     \n",
      "                                                                 lstm_4[0][2]                     \n",
      "                                                                 concatenate_5[2][0]              \n",
      "                                                                 lstm_4[1][1]                     \n",
      "                                                                 lstm_4[1][2]                     \n",
      "                                                                 concatenate_5[3][0]              \n",
      "                                                                 lstm_4[2][1]                     \n",
      "                                                                 lstm_4[2][2]                     \n",
      "                                                                 concatenate_5[4][0]              \n",
      "                                                                 lstm_4[3][1]                     \n",
      "                                                                 lstm_4[3][2]                     \n",
      "                                                                 concatenate_5[5][0]              \n",
      "                                                                 lstm_4[4][1]                     \n",
      "                                                                 lstm_4[4][2]                     \n",
      "                                                                 concatenate_5[6][0]              \n",
      "                                                                 lstm_4[5][1]                     \n",
      "                                                                 lstm_4[5][2]                     \n",
      "                                                                 concatenate_5[7][0]              \n",
      "                                                                 lstm_4[6][1]                     \n",
      "                                                                 lstm_4[6][2]                     \n",
      "                                                                 concatenate_5[8][0]              \n",
      "                                                                 lstm_4[7][1]                     \n",
      "                                                                 lstm_4[7][2]                     \n",
      "                                                                 concatenate_5[9][0]              \n",
      "                                                                 lstm_4[8][1]                     \n",
      "                                                                 lstm_4[8][2]                     \n",
      "                                                                 concatenate_5[10][0]             \n",
      "                                                                 lstm_4[9][1]                     \n",
      "                                                                 lstm_4[9][2]                     \n",
      "                                                                 concatenate_5[11][0]             \n",
      "                                                                 lstm_4[10][1]                    \n",
      "                                                                 lstm_4[10][2]                    \n",
      "                                                                 concatenate_5[12][0]             \n",
      "                                                                 lstm_4[11][1]                    \n",
      "                                                                 lstm_4[11][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1, 100)       0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1, 100)       0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1, 100)       0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1, 100)       0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1, 100)       0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1, 100)       0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1, 100)       0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1, 100)       0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1, 100)       0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1, 100)       0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 1, 100)       0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 1, 100)       0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 10504)        4212104     lstm_4[0][0]                     \n",
      "                                                                 lstm_4[1][0]                     \n",
      "                                                                 lstm_4[2][0]                     \n",
      "                                                                 lstm_4[3][0]                     \n",
      "                                                                 lstm_4[4][0]                     \n",
      "                                                                 lstm_4[5][0]                     \n",
      "                                                                 lstm_4[6][0]                     \n",
      "                                                                 lstm_4[7][0]                     \n",
      "                                                                 lstm_4[8][0]                     \n",
      "                                                                 lstm_4[9][0]                     \n",
      "                                                                 lstm_4[10][0]                    \n",
      "                                                                 lstm_4[11][0]                    \n",
      "                                                                 lstm_4[12][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 13, 10504)    0           dense_8[0][0]                    \n",
      "                                                                 dense_8[1][0]                    \n",
      "                                                                 dense_8[2][0]                    \n",
      "                                                                 dense_8[3][0]                    \n",
      "                                                                 dense_8[4][0]                    \n",
      "                                                                 dense_8[5][0]                    \n",
      "                                                                 dense_8[6][0]                    \n",
      "                                                                 dense_8[7][0]                    \n",
      "                                                                 dense_8[8][0]                    \n",
      "                                                                 dense_8[9][0]                    \n",
      "                                                                 dense_8[10][0]                   \n",
      "                                                                 dense_8[11][0]                   \n",
      "                                                                 dense_8[12][0]                   \n",
      "==================================================================================================\n",
      "Total params: 9,336,225\n",
      "Trainable params: 9,336,225\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "250/250 [==============================] - 71s 284ms/step - loss: 6.1728 - acc: 0.2506 - val_loss: 6.1232 - val_acc: 0.2312\n",
      "Epoch 2/30\n",
      "250/250 [==============================] - 67s 267ms/step - loss: 5.4214 - acc: 0.2795 - val_loss: 5.8582 - val_acc: 0.2573\n",
      "Epoch 3/30\n",
      "250/250 [==============================] - 67s 267ms/step - loss: 4.9711 - acc: 0.3103 - val_loss: 5.4816 - val_acc: 0.2833\n",
      "Epoch 4/30\n",
      "250/250 [==============================] - 67s 267ms/step - loss: 4.3883 - acc: 0.3613 - val_loss: 5.0999 - val_acc: 0.3363\n",
      "Epoch 5/30\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 3.8325 - acc: 0.4081 - val_loss: 4.8786 - val_acc: 0.3590\n",
      "Epoch 6/30\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 3.3405 - acc: 0.4433 - val_loss: 4.7345 - val_acc: 0.3798\n",
      "Epoch 7/30\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 2.9147 - acc: 0.4704 - val_loss: 4.6457 - val_acc: 0.3948\n",
      "Epoch 8/30\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 2.5336 - acc: 0.4982 - val_loss: 4.5952 - val_acc: 0.4046\n",
      "Epoch 9/30\n",
      "250/250 [==============================] - 67s 269ms/step - loss: 2.1983 - acc: 0.5279 - val_loss: 4.5849 - val_acc: 0.4160\n",
      "Epoch 10/30\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 1.9139 - acc: 0.5587 - val_loss: 4.5653 - val_acc: 0.4212\n",
      "Epoch 11/30\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 1.6669 - acc: 0.5938 - val_loss: 4.5851 - val_acc: 0.4239\n",
      "Epoch 12/30\n",
      "250/250 [==============================] - 67s 269ms/step - loss: 1.4650 - acc: 0.6289 - val_loss: 4.5878 - val_acc: 0.4270\n",
      "Epoch 13/30\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 1.2934 - acc: 0.6602 - val_loss: 4.6078 - val_acc: 0.4303\n",
      "Epoch 14/30\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 1.1539 - acc: 0.6865 - val_loss: 4.6049 - val_acc: 0.4336\n",
      "Epoch 15/30\n",
      "250/250 [==============================] - 67s 269ms/step - loss: 1.0343 - acc: 0.7113 - val_loss: 4.6773 - val_acc: 0.4326\n",
      "Epoch 16/30\n",
      "250/250 [==============================] - 67s 269ms/step - loss: 0.9351 - acc: 0.7323 - val_loss: 4.6882 - val_acc: 0.4371\n",
      "Epoch 17/30\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 0.8511 - acc: 0.7499 - val_loss: 4.7113 - val_acc: 0.4365\n",
      "Epoch 18/30\n",
      "250/250 [==============================] - 67s 266ms/step - loss: 0.7859 - acc: 0.7630 - val_loss: 4.7599 - val_acc: 0.4382\n",
      "Epoch 19/30\n",
      "250/250 [==============================] - 67s 267ms/step - loss: 0.7247 - acc: 0.7752 - val_loss: 4.7720 - val_acc: 0.4405\n",
      "Epoch 20/30\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 0.6760 - acc: 0.7844 - val_loss: 4.8407 - val_acc: 0.4384\n",
      "Epoch 21/30\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 0.6319 - acc: 0.7930 - val_loss: 4.8453 - val_acc: 0.4426\n",
      "Epoch 22/30\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 0.5944 - acc: 0.7992 - val_loss: 4.9230 - val_acc: 0.4439\n",
      "Epoch 23/30\n",
      "250/250 [==============================] - 67s 267ms/step - loss: 0.5655 - acc: 0.8051 - val_loss: 4.9518 - val_acc: 0.4413\n",
      "Epoch 24/30\n",
      "250/250 [==============================] - 67s 267ms/step - loss: 0.5418 - acc: 0.8085 - val_loss: 5.0004 - val_acc: 0.4364\n",
      "Epoch 25/30\n",
      "250/250 [==============================] - 67s 267ms/step - loss: 0.5135 - acc: 0.8163 - val_loss: 4.9786 - val_acc: 0.4392\n",
      "Epoch 26/30\n",
      "250/250 [==============================] - 67s 267ms/step - loss: 0.4955 - acc: 0.8176 - val_loss: 5.0598 - val_acc: 0.4416\n",
      "Epoch 27/30\n",
      "250/250 [==============================] - 67s 267ms/step - loss: 0.4803 - acc: 0.8199 - val_loss: 5.0724 - val_acc: 0.4424\n",
      "Epoch 28/30\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 0.4665 - acc: 0.8217 - val_loss: 5.1006 - val_acc: 0.4437\n",
      "Epoch 29/30\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 0.4553 - acc: 0.8239 - val_loss: 5.0926 - val_acc: 0.4418\n",
      "Epoch 30/30\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 0.4437 - acc: 0.8259 - val_loss: 5.1646 - val_acc: 0.4439\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "z=np.zeros((len(encoder_inputs),LATENT_DIM_DECODER)) # initial [s, c]\n",
    "r=model.fit([encoder_inputs,decoder_inputs,z,z],decoder_targets_one_hot,batch_size=BATCH_SIZE,epochs=EPOCHS,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot some data\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['acc'], label='acc')\n",
    "plt.plot(r.history['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create another model\n",
    "# that can take in the RNN state and previous word as input\n",
    "# and accept a T=1 sequence.\n",
    "\n",
    "# The encoder will be stand-alone\n",
    "# From this we will get our initial decoder hidden state\n",
    "# i.e. h(1), ..., h(Tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model=Model(encoder_input_placeholder,encoder_outputs)\n",
    "\n",
    "# next we define a T=1 decoder model\n",
    "encoder_outputs_as_input = Input(shape=(max_input_length,LATENT_DIM*2))\n",
    "decoder_input_single=Input(shape=(1,))\n",
    "# get the embedding for the last word input \n",
    "decoder_input_single_x = decoder_embdding(decoder_input_single)\n",
    "\n",
    "# no need to loop over attention steps this time because there is only one step\n",
    "# (h, st_1)\n",
    "context = one_step_attention(encoder_outputs_as_input,initial_s)\n",
    "\n",
    "# combine context with last word\n",
    "decoder_lstm_input = context_last_word_concat_layer([context, decoder_input_single_x])\n",
    "\n",
    "# lstm and final dense\n",
    "o,s,c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s,initial_c])\n",
    "# get output word probability\n",
    "decoder_ouputs =  decoder_dense(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: we don't really need the final stack and tranpose\n",
    "# because there's only 1 output\n",
    "# it is already of size N x D\n",
    "# no need to make it 1 x N x D --> N x 1 x D\n",
    "\n",
    "\n",
    "# create the model object\n",
    "decoder_model=Model([decoder_input_single,\n",
    "                     encoder_outputs_as_input,\n",
    "                     initial_s,\n",
    "                     initial_c],\n",
    "                    [decoder_ouputs,s,c] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map indexes back into real words\n",
    "# so we can view the results\n",
    "idx2word_eng={v:k for k,v in word2idx_input.items()}\n",
    "idx2word_trans={v:k for k,v in word2idx_target.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8764,\n",
       " array([[  0,   0,   7,   5,  68, 397]], dtype=int32),\n",
       " \"I'm a good cook.\")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.random.choice(len(input_texts))\n",
    "input_seq = encoder_inputs[i:i+1]\n",
    "i,input_seq,input_texts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    enc_out = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Populate the first character of target sequence with the start character. \n",
    "    # NOTE: tokenizer lower-cases all words\n",
    "    target_seq[0,0]=word2idx_target['<sos>']\n",
    "\n",
    "    # if we get this we break\n",
    "    eos = word2idx_target['<eos>']\n",
    "\n",
    "    # initialising s & c to be a bunch of zeros.\n",
    "    # This is different from regular Seq2Seq where we get the initial state from the encoder.\n",
    "    # [s, c] will be updated in each loop iteration\n",
    "    s=np.zeros((1,LATENT_DIM_DECODER))\n",
    "    c=np.zeros((1,LATENT_DIM_DECODER))\n",
    "\n",
    "    # Create the translation\n",
    "    output_translation=[]\n",
    "    for _ in range(max_target_length):\n",
    "        o,s,c = decoder_model.predict([target_seq,\n",
    "                                       enc_out,\n",
    "                                       s,\n",
    "                                       c])\n",
    "\n",
    "        # Get next word\n",
    "        idx = np.argmax(o.flatten())\n",
    "\n",
    "        # End sentence of EOS\n",
    "        if idx == eos:\n",
    "            break\n",
    "        word = ''\n",
    "        if idx>0:\n",
    "            word = idx2word_trans[idx]\n",
    "            output_translation.append(word)\n",
    "        # Update the decoder input\n",
    "        # which is just the word just generated\n",
    "        target_seq[0,0]=idx\n",
    "    return ' '.join(output_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Can I try it?\n",
      "Predicted translation: ¿puedo intentar?\n",
      "Actual translation: ¿Puedo intentar? <eos>\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(len(input_texts))\n",
    "input_seq = encoder_inputs[i:i+1]\n",
    "translation = decode_sequence(input_seq)\n",
    "print('-')\n",
    "print('Input sentence:', input_texts[i])\n",
    "print('Predicted translation:', translation)\n",
    "print('Actual translation:', target_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
