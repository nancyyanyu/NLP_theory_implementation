{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from util import get_wikipedia_data, find_analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Glove(object):\n",
    "    def __init__(self, D, V, context_sz):\n",
    "        # word embedding dimension\n",
    "        self.D = D\n",
    "        self.V = V\n",
    "        self.context_sz = context_sz\n",
    "\n",
    "    def build_cc(self, sentences, cc_matrix=None):\n",
    "        V = self.V\n",
    "        D = self.D\n",
    "\n",
    "        if not os.path.isfile(cc_matrix):\n",
    "            X = np.zeros((V, V))\n",
    "            N = len(sentences)\n",
    "            it = 0\n",
    "\n",
    "            for sentence in sentences:\n",
    "                it += 1\n",
    "                if it % 100 == 0:\n",
    "                    print(\"processed: {} / {}\".format(it, N))\n",
    "\n",
    "                n = len(sentence)\n",
    "                for i, wi in enumerate(sentence):\n",
    "                    start = max(0, i-self.context_sz)\n",
    "                    end = min(n, self.context_sz+i)\n",
    "\n",
    "                    # we can either choose only one side as context, or both\n",
    "                    # here we are doing both\n",
    "                    # make sure \"start\" and \"end\" tokens are part of some context\n",
    "                    # otherwise their f(X) will be 0 (denominator in bias update)\n",
    "                    if i < self.context_sz:\n",
    "                        # i's distance to 'start'\n",
    "                        point = 1.0 / (1 + i)\n",
    "                        X[wi, 0] += point\n",
    "                        X[0, wi] += point\n",
    "\n",
    "                    if i > n-self.context_sz:\n",
    "                        # i's distance to 'end'\n",
    "                        point = 1.0 / (n-i)\n",
    "                        X[wi, 1] += point\n",
    "                        X[1, wi] += point\n",
    "\n",
    "                    # left side - distance between start and i\n",
    "                    for j in range(start, i):\n",
    "                        wj = sentence[j]\n",
    "                        point = 1.0 / (i-j)\n",
    "                        X[wi, wj] += point\n",
    "                        X[wj, wi] += point\n",
    "\n",
    "                    # right side - distance between i and end\n",
    "                    for j in range(i+1, end):\n",
    "                        wj = sentence[j]\n",
    "                        point = 1.0 / (j-i)\n",
    "                        X[wi, wj] += point\n",
    "                        X[wj, wi] += point\n",
    "\n",
    "            # save to local file\n",
    "            np.savez(cc_matrix, X)\n",
    "        else:\n",
    "            X = np.load(cc_matrix)\n",
    "            X = X.f.arr_0\n",
    "        print(\"max in X:\", X.max())\n",
    "        return X\n",
    "\n",
    "    def fit(self, sentences, cc_matrix, lr=1e-4, alpha=0.75, Xmax=100, epochs=1, reg=0.01, gradient_descent=False):\n",
    "        # build co-occurrence matrix\n",
    "        # paper calls it X, so we will call it X, instead of calling\n",
    "        # the training data X\n",
    "        X = self.build_cc(sentences, cc_matrix)\n",
    "        V = self.V\n",
    "        D = self.D\n",
    "\n",
    "        # weighting\n",
    "        # fX=(X/Xmax)^alpha if X<Xmax else 1\n",
    "        fX = np.zeros((V, V))\n",
    "        fX[X < Xmax] = (X[X < Xmax] / float(Xmax))**alpha\n",
    "        fX[X >= Xmax] = 1\n",
    "        print(\"max in fX:\", fX.max())\n",
    "\n",
    "        # target\n",
    "        logX = np.log(X+1)\n",
    "        print(\"max in log X:\", logX.max())\n",
    "\n",
    "        # initialize weights\n",
    "        W = np.random.randn(V, D)/np.sqrt(V+D)\n",
    "        U = np.random.randn(V, D)/np.sqrt(V+D)\n",
    "        b = np.zeros(V)\n",
    "        c = np.zeros(V)\n",
    "        mu = logX.mean()\n",
    "\n",
    "        costs = []\n",
    "        for epoch in range(epochs):\n",
    "            \"\"\"\n",
    "            J=\\sum_i \\sum_j f(X_{ij})(w_i^Tu_j-\\log{X_{ij}})^2\n",
    "            \"\"\"\n",
    "            # b is supposed to be a column vector and c is supposed to be a row vector.\n",
    "            target_hat = W.dot(U.T)+b.reshape(V, 1)+c.reshape(1, V)+mu\n",
    "            J = (fX*((target_hat-logX)**2)).sum()\n",
    "            print(\"epoch:\", epoch, \"costs:\", int(J))\n",
    "            costs.append(J)\n",
    "\n",
    "            if not gradient_descent:\n",
    "                \"\"\"ALS method\"\"\"\n",
    "                # update W\n",
    "                for i in range(V):\n",
    "                    matrix = reg*np.eye(D) + (fX[i, :]*U.T).dot(U)\n",
    "                    vector = (fX[i, :]*(logX[i, :]-b[i]-c-mu)).dot(U)\n",
    "                    W[i] = np.linalg.solve(matrix, vector)\n",
    "\n",
    "                # update b\n",
    "                for i in range(V):\n",
    "                    denominator = fX[i, :].sum()\n",
    "                    numerator = fX[i, :].dot(logX[i, :]-W[i].dot(U.T)-c-mu)\n",
    "                    b[i] = numerator / denominator/(reg+1)\n",
    "\n",
    "                # update U\n",
    "                for j in range(V):\n",
    "                    matrix = reg*np.eye(D)+(fX[:, j]*W.T).dot(W)\n",
    "                    vector = (fX[:, j]*(logX[:, j]-b-c[j]-mu)).dot(W)\n",
    "                    U[j] = np.linalg.solve(matrix, vector)\n",
    "\n",
    "                # update c\n",
    "                for j in range(V):\n",
    "                    denominator = fX[:, j].sum()\n",
    "                    numerator = fX[:, j].dot(logX[:, j]-W.dot(U[j])-b-mu)\n",
    "                    c[j] = numerator / denominator / (reg+1)\n",
    "            else:\n",
    "                \"\"\"Gradient descent\"\"\"\n",
    "                delta = target_hat-logX\n",
    "                oldW = W.copy()\n",
    "\n",
    "                # update W\n",
    "                for i in range(V):\n",
    "                    W[i] -= lr*(fX[i, :]*delta[i, :]).dot(U)\n",
    "                W -= lr*reg*W\n",
    "\n",
    "                # update b\n",
    "                for i in range(V):\n",
    "                    b[i] -= lr*fX[i, :].dot(delta[i, :])\n",
    "                b -= lr*reg*b\n",
    "\n",
    "                # update U\n",
    "                for j in range(V):\n",
    "                    U[j] -= lr*(fX[:, j]*delta[:, j]).dot(oldW)\n",
    "                U -= lr*reg*U\n",
    "\n",
    "                # update c\n",
    "                for j in range(V):\n",
    "                    c[j] -= lr*fX[:, j].dot(delta[:, j])\n",
    "                c -= lr*reg*c\n",
    "\n",
    "        self.W = W\n",
    "        self.U = U\n",
    "\n",
    "        plt.plot(costs)\n",
    "        plt.show()\n",
    "\n",
    "    def save(self, fn):\n",
    "        arrays = [self.W, self.U.T]\n",
    "        np.savez(fn, *arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_files = 100\n",
    "we_file = \"./model/glove_model_50.npz\"\n",
    "w2i_file = \"./model/glove_word2idx_50.json\"\n",
    "# remember, only the co-occurrence matrix is needed for training\n",
    "cc_matrix = \"./model/cc_matrix_{}.npz\".format(n_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word2idx\n",
    "if os.path.isfile(cc_matrix):\n",
    "    with open(w2i_file, 'r') as f:\n",
    "        word2idx = json.load(f)\n",
    "    sentences = []  # dummy - we won't actually use it\n",
    "\n",
    "else:\n",
    "    sentences, word2idx = get_wikipedia_data(n_files, n_vocab=2000)\n",
    "    with open(w2i_file, 'w') as f:\n",
    "        json.dump(word2idx, f)\n",
    "\n",
    "V = len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max in X: 75446433.19258384\n",
      "max in fX: 1.0\n",
      "max in log X: 18.13893348152565\n",
      "epoch: 0 costs: 5745302\n",
      "epoch: 1 costs: 349579\n",
      "epoch: 2 costs: 212141\n",
      "epoch: 3 costs: 196484\n",
      "epoch: 4 costs: 191421\n",
      "epoch: 5 costs: 189132\n",
      "epoch: 6 costs: 187896\n",
      "epoch: 7 costs: 187149\n",
      "epoch: 8 costs: 186661\n",
      "epoch: 9 costs: 186320\n",
      "epoch: 10 costs: 186072\n",
      "epoch: 11 costs: 185885\n",
      "epoch: 12 costs: 185739\n",
      "epoch: 13 costs: 185624\n",
      "epoch: 14 costs: 185531\n",
      "epoch: 15 costs: 185454\n",
      "epoch: 16 costs: 185391\n",
      "epoch: 17 costs: 185338\n",
      "epoch: 18 costs: 185293\n",
      "epoch: 19 costs: 185254\n",
      "epoch: 20 costs: 185221\n",
      "epoch: 21 costs: 185193\n",
      "epoch: 22 costs: 185168\n",
      "epoch: 23 costs: 185146\n",
      "epoch: 24 costs: 185126\n",
      "epoch: 25 costs: 185109\n",
      "epoch: 26 costs: 185094\n",
      "epoch: 27 costs: 185080\n",
      "epoch: 28 costs: 185068\n",
      "epoch: 29 costs: 185057\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train and save the GloVe model\n",
    "gv = Glove(D=100, V=V, context_sz=10)\n",
    "\n",
    "# ALS\n",
    "gv.fit(sentences, cc_matrix=cc_matrix, lr=1e-4,\n",
    "       reg=0.01, epochs=20, gradient_descent=False)\n",
    "\n",
    "# GD\n",
    "# gv.fit(\n",
    "#     sentences,\n",
    "#     cc_matrix=cc_matrix,\n",
    "#     lr=5e-4,\n",
    "#     reg=0.1,\n",
    "#     epochs=500,\n",
    "#     gradient_descent=True,\n",
    "# )\n",
    "gv.save(we_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "closest match by euclidean distance: queen\n",
      "king - man = queen - woman\n",
      "\n",
      "closest match by cosine distance: queen\n",
      "king - man = queen - woman\n",
      "\n",
      "closest match by euclidean distance: england\n",
      "france - paris = england - london\n",
      "\n",
      "closest match by cosine distance: england\n",
      "france - paris = england - london\n",
      "\n",
      "closest match by euclidean distance: italy\n",
      "france - paris = italy - rome\n",
      "\n",
      "closest match by cosine distance: italy\n",
      "france - paris = italy - rome\n",
      "\n",
      "closest match by euclidean distance: berlin\n",
      "paris - france = berlin - italy\n",
      "\n",
      "closest match by cosine distance: rome\n",
      "paris - france = rome - italy\n",
      "\n",
      "closest match by euclidean distance: england\n",
      "france - french = england - english\n",
      "\n",
      "closest match by cosine distance: england\n",
      "france - french = england - english\n",
      "\n",
      "closest match by euclidean distance: china\n",
      "japan - japanese = china - chinese\n",
      "\n",
      "closest match by cosine distance: china\n",
      "japan - japanese = china - chinese\n",
      "\n",
      "closest match by euclidean distance: italy\n",
      "japan - japanese = italy - italian\n",
      "\n",
      "closest match by cosine distance: italy\n",
      "japan - japanese = italy - italian\n",
      "\n",
      "closest match by euclidean distance: australia\n",
      "japan - japanese = australia - australian\n",
      "\n",
      "closest match by cosine distance: australia\n",
      "japan - japanese = australia - australian\n",
      "\n",
      "closest match by euclidean distance: august\n",
      "december - november = august - june\n",
      "\n",
      "closest match by cosine distance: august\n",
      "december - november = august - june\n",
      "\n",
      "\n",
      "*************************\n",
      "closest match by euclidean distance: queen\n",
      "king - man = queen - woman\n",
      "\n",
      "closest match by cosine distance: queen\n",
      "king - man = queen - woman\n",
      "\n",
      "closest match by euclidean distance: england\n",
      "france - paris = england - london\n",
      "\n",
      "closest match by cosine distance: england\n",
      "france - paris = england - london\n",
      "\n",
      "closest match by euclidean distance: italy\n",
      "france - paris = italy - rome\n",
      "\n",
      "closest match by cosine distance: italy\n",
      "france - paris = italy - rome\n",
      "\n",
      "closest match by euclidean distance: berlin\n",
      "paris - france = berlin - italy\n",
      "\n",
      "closest match by cosine distance: rome\n",
      "paris - france = rome - italy\n",
      "\n",
      "closest match by euclidean distance: england\n",
      "france - french = england - english\n",
      "\n",
      "closest match by cosine distance: england\n",
      "france - french = england - english\n",
      "\n",
      "closest match by euclidean distance: china\n",
      "japan - japanese = china - chinese\n",
      "\n",
      "closest match by cosine distance: china\n",
      "japan - japanese = china - chinese\n",
      "\n",
      "closest match by euclidean distance: italy\n",
      "japan - japanese = italy - italian\n",
      "\n",
      "closest match by cosine distance: italy\n",
      "japan - japanese = italy - italian\n",
      "\n",
      "closest match by euclidean distance: australia\n",
      "japan - japanese = australia - australian\n",
      "\n",
      "closest match by cosine distance: australia\n",
      "japan - japanese = australia - australian\n",
      "\n",
      "closest match by euclidean distance: august\n",
      "december - november = august - june\n",
      "\n",
      "closest match by cosine distance: august\n",
      "december - november = august - june\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load back model\n",
    "npz = np.load(we_file)\n",
    "W1, W2 = npz['arr_0'], npz['arr_1']\n",
    "\n",
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "\n",
    "for We in ((W1+W2.T)/2, np.hstack([W1, W2.T])):\n",
    "    print(\"*************************\")\n",
    "    find_analogies('king', 'man', 'woman', We, word2idx, idx2word)\n",
    "    find_analogies('france', 'paris', 'london', We, word2idx, idx2word)\n",
    "    find_analogies('france', 'paris', 'rome', We, word2idx, idx2word)\n",
    "    find_analogies('paris', 'france', 'italy', We, word2idx, idx2word)\n",
    "    find_analogies('france', 'french', 'english', We, word2idx, idx2word)\n",
    "    find_analogies('japan', 'japanese', 'chinese', We, word2idx, idx2word)\n",
    "    find_analogies('japan', 'japanese', 'italian', We, word2idx, idx2word)\n",
    "    find_analogies('japan', 'japanese', 'australian', We, word2idx, idx2word)\n",
    "    find_analogies('december', 'november', 'june', We, word2idx, idx2word)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloveTF(Glove):\n",
    "    def __init__(self, D, V, context_sz):\n",
    "        super().__init__(D, V, context_sz)\n",
    "        pass\n",
    "\n",
    "    def fit(self, sentences, cc_matrix, lr=1e-4, alpha=0.75, Xmax=100, epochs=1, reg=0.01, gradient_descent=False):\n",
    "        # build co-occurrence matrix\n",
    "        # paper calls it X, so we will call it X, instead of calling\n",
    "        # the training data X\n",
    "        X = self.build_cc(sentences, cc_matrix)\n",
    "        V = self.V\n",
    "        D = self.D\n",
    "\n",
    "        # weighting\n",
    "        # fX=(X/Xmax)^alpha if X<Xmax else 1\n",
    "        fX = np.zeros((V, V))\n",
    "        fX[X < Xmax] = (X[X < Xmax] / float(Xmax))**alpha\n",
    "        fX[X >= Xmax] = 1\n",
    "        print(\"max in fX:\", fX.max())\n",
    "\n",
    "        # target\n",
    "        logX = np.log(X+1)\n",
    "        print(\"max in log X:\", logX.max())\n",
    "\n",
    "        # initialize weights\n",
    "        W = np.random.randn(V, D)/np.sqrt(V+D)\n",
    "        U = np.random.randn(V, D)/np.sqrt(V+D)\n",
    "        b = np.zeros(V)\n",
    "        c = np.zeros(V)\n",
    "        mu = logX.mean()\n",
    "\n",
    "        # initialize weights, inputs, targets placeholders\n",
    "        tfW = tf.Variable(W.astype(np.float32))\n",
    "        tfU = tf.Variable(U.astype(np.float32))\n",
    "        tfb = tf.Variable(b.reshape(V, 1).astype(np.float32))\n",
    "        tfc = tf.Variable(c.reshape(1, V).astype(np.float32))\n",
    "        \n",
    "\n",
    "        plt.plot(costs)\n",
    "        plt.show()\n",
    "\n",
    "    def save(self, fn):\n",
    "        arrays = [self.W, self.U.T]\n",
    "        np.savez(fn, *arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = GloveTF(100, V, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max in X: 75446433.19258384\n",
      "max in fX: 1.0\n",
      "max in log X: 18.13893348152565\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'compact'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-ed372651eb30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mtfb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mtfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtfLogX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mtffX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'compact'"
     ]
    }
   ],
   "source": [
    "lr=1e-4 \n",
    "alpha=0.75\n",
    "Xmax=100\n",
    "reg=0.01\n",
    "\n",
    "X = self.build_cc(sentences, cc_matrix)\n",
    "V = self.V\n",
    "D = self.D\n",
    "\n",
    "# weighting\n",
    "# fX=(X/Xmax)^alpha if X<Xmax else 1\n",
    "fX = np.zeros((V, V))\n",
    "fX[X < Xmax] = (X[X < Xmax] / float(Xmax))**alpha\n",
    "fX[X >= Xmax] = 1\n",
    "print(\"max in fX:\", fX.max())\n",
    "\n",
    "# target\n",
    "logX = np.log(X+1)\n",
    "print(\"max in log X:\", logX.max())\n",
    "\n",
    "# initialize weights\n",
    "W = np.random.randn(V, D)/np.sqrt(V+D)\n",
    "U = np.random.randn(V, D)/np.sqrt(V+D)\n",
    "b = np.zeros(V)\n",
    "c = np.zeros(V)\n",
    "mu = logX.mean()\n",
    "\n",
    "# initialize weights, inputs, targets placeholders\n",
    "tfW = tf.Variable(W.astype(np.float32))\n",
    "tfU = tf.Variable(U.astype(np.float32))\n",
    "tfb = tf.Variable(b.reshape(V, 1).astype(np.float32))\n",
    "tfc = tf.Variable(c.reshape(1, V).astype(np.float32))\n",
    "tfLog = tf.constant(logX,shape=(V,V),dtype=tf.float32)\n",
    "tffX = tf.constant(fX,shape=(V,V),dtype=tf.float32)\n",
    "\n",
    "delta = tf.matmul(tfW ,tf.transpose(a=tfU))+tfb+tfc+mu-tfLog\n",
    "J=tf.math.reduce_sum(tffX*delta*delta) + reg*tf.math.reduce_sum(tfW**2)+ reg*tf.math.reduce_sum(tfU**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2001, 2001])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08009681, 0.31226675, 0.85673032],\n",
       "       [0.90261428, 0.92750757, 0.43860123],\n",
       "       [0.48060577, 0.46872246, 0.92006421],\n",
       "       [0.07249769, 0.79180378, 0.48886042]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(4,3)*np.ones((1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=5745253.5>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Countries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_file='./model/glove_model_50.npz'\n",
    "w2i_file='./model/glove_word2idx_50.json'\n",
    "\n",
    "words = ['japan', 'japanese', 'england', 'english', 'australia', 'australian', 'china', 'chinese', 'italy', 'italian', 'french', 'france', 'spain', 'spanish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(w2i_file, 'r') as f:\n",
    "    word2idx = json.load(f)\n",
    "npz = np.load(we_file)\n",
    "idx = [word2idx[w] for w in words]\n",
    "\n",
    "W1,W2=npz['arr_0'],npz['arr_1']\n",
    "\n",
    "We=(W1+W2.T)/2\n",
    "tnse = TSNE()\n",
    "Z= tnse.fit_transform(We)\n",
    "Z = Z[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:3: MatplotlibDeprecationWarning: The 's' parameter of annotate() has been renamed 'text' since Matplotlib 3.3; support for the old name will be dropped two minor releases later.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Z[:,0],Z[:,1])\n",
    "for i in range(len(words)):\n",
    "    plt.annotate(s=words[i],xy=(Z[i,0],Z[i,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training GloVe with SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloveSVD(Glove):\n",
    "    def __init__(self,D,V,context_sz):\n",
    "        super().__init__(D,V,context_sz)\n",
    "        pass\n",
    "    \n",
    "    def fit(self,sentences,cc_matrix=None):\n",
    "        X = self.build_cc(sentences, cc_matrix)\n",
    "        V=self.V\n",
    "        D=self.D\n",
    "        \n",
    "        # target\n",
    "        logX=np.log(X+1)\n",
    "        print(\"max in log(X):\", logX.max())\n",
    "\n",
    "        # subtract mean\n",
    "        mu=np.mean(logX)\n",
    "\n",
    "        model = TruncatedSVD(n_components=D)\n",
    "        Z=model.fit_transform(logX-mu)\n",
    "\n",
    "        S=np.diag(model.explained_variance_)\n",
    "        S_inv = np.linalg.inv(S)\n",
    "\n",
    "        self.W=Z.dot(S_inv)\n",
    "\n",
    "        self.U=model.components_.T\n",
    "\n",
    "        delta = self.W.dot(S).dot(self.U.T)+mu-logX\n",
    "        cost=(delta**2).sum()\n",
    "        print(\"svd cost:\", cost)\n",
    "        \n",
    "    def save(self, fn):\n",
    "        # function word_analogies expects a (V,D) matrx and a (D,V) matrix\n",
    "        arrays = [self.W, self.U.T]\n",
    "        np.savez(fn, *arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_files = 100\n",
    "we_file = \"./model/glove_model_50.npz\"\n",
    "w2i_file = \"./model/glove_word2idx_50.json\"\n",
    "# remember, only the co-occurrence matrix is needed for training\n",
    "cc_matrix = \"./model/cc_matrix_{}.npz\".format(n_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word2idx\n",
    "if os.path.isfile(cc_matrix):\n",
    "    with open(w2i_file, 'r') as f:\n",
    "        word2idx = json.load(f)\n",
    "    sentences = []  # dummy - we won't actually use it\n",
    "\n",
    "else:\n",
    "    sentences, word2idx = get_wikipedia_data(n_files, n_vocab=2000)\n",
    "    with open(w2i_file, 'w') as f:\n",
    "        json.dump(word2idx, f)\n",
    "\n",
    "V = len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max in X: 75446433.19258384\n",
      "max in log(X): 18.13893348152565\n",
      "svd cost: 857676.7831010601\n"
     ]
    }
   ],
   "source": [
    "# train and save the GloVe model\n",
    "gSVD = GloveSVD(D=100, V=V, context_sz=10)\n",
    "\n",
    "# ALS\n",
    "gSVD.fit(sentences, cc_matrix=cc_matrix)\n",
    "\n",
    "gSVD.save(we_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "closest match by euclidean distance: queen\n",
      "king - man = queen - woman\n",
      "\n",
      "closest match by cosine distance: queen\n",
      "king - man = queen - woman\n",
      "\n",
      "closest match by euclidean distance: britain\n",
      "france - paris = britain - london\n",
      "\n",
      "closest match by cosine distance: scotland\n",
      "france - paris = scotland - london\n",
      "\n",
      "closest match by euclidean distance: italy\n",
      "france - paris = italy - rome\n",
      "\n",
      "closest match by cosine distance: italy\n",
      "france - paris = italy - rome\n",
      "\n",
      "closest match by euclidean distance: rome\n",
      "paris - france = rome - italy\n",
      "\n",
      "closest match by cosine distance: rome\n",
      "paris - france = rome - italy\n",
      "\n",
      "closest match by euclidean distance: england\n",
      "france - french = england - english\n",
      "\n",
      "closest match by cosine distance: england\n",
      "france - french = england - english\n",
      "\n",
      "closest match by euclidean distance: china\n",
      "japan - japanese = china - chinese\n",
      "\n",
      "closest match by cosine distance: china\n",
      "japan - japanese = china - chinese\n",
      "\n",
      "closest match by euclidean distance: italy\n",
      "japan - japanese = italy - italian\n",
      "\n",
      "closest match by cosine distance: italy\n",
      "japan - japanese = italy - italian\n",
      "\n",
      "closest match by euclidean distance: australia\n",
      "japan - japanese = australia - australian\n",
      "\n",
      "closest match by cosine distance: australia\n",
      "japan - japanese = australia - australian\n",
      "\n",
      "closest match by euclidean distance: august\n",
      "december - november = august - june\n",
      "\n",
      "closest match by cosine distance: august\n",
      "december - november = august - june\n",
      "\n",
      "\n",
      "*************************\n",
      "closest match by euclidean distance: queen\n",
      "king - man = queen - woman\n",
      "\n",
      "closest match by cosine distance: queen\n",
      "king - man = queen - woman\n",
      "\n",
      "closest match by euclidean distance: britain\n",
      "france - paris = britain - london\n",
      "\n",
      "closest match by cosine distance: scotland\n",
      "france - paris = scotland - london\n",
      "\n",
      "closest match by euclidean distance: italy\n",
      "france - paris = italy - rome\n",
      "\n",
      "closest match by cosine distance: italy\n",
      "france - paris = italy - rome\n",
      "\n",
      "closest match by euclidean distance: rome\n",
      "paris - france = rome - italy\n",
      "\n",
      "closest match by cosine distance: rome\n",
      "paris - france = rome - italy\n",
      "\n",
      "closest match by euclidean distance: england\n",
      "france - french = england - english\n",
      "\n",
      "closest match by cosine distance: england\n",
      "france - french = england - english\n",
      "\n",
      "closest match by euclidean distance: china\n",
      "japan - japanese = china - chinese\n",
      "\n",
      "closest match by cosine distance: china\n",
      "japan - japanese = china - chinese\n",
      "\n",
      "closest match by euclidean distance: italy\n",
      "japan - japanese = italy - italian\n",
      "\n",
      "closest match by cosine distance: italy\n",
      "japan - japanese = italy - italian\n",
      "\n",
      "closest match by euclidean distance: australia\n",
      "japan - japanese = australia - australian\n",
      "\n",
      "closest match by cosine distance: australia\n",
      "japan - japanese = australia - australian\n",
      "\n",
      "closest match by euclidean distance: august\n",
      "december - november = august - june\n",
      "\n",
      "closest match by cosine distance: august\n",
      "december - november = august - june\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load back model\n",
    "npz = np.load(we_file)\n",
    "W1, W2 = npz['arr_0'], npz['arr_1']\n",
    "\n",
    "idx2word = {v: k for k, v in word2idx.items()}\n",
    "\n",
    "for We in ((W1+W2.T)/2, np.hstack([W1, W2.T])):\n",
    "    print(\"*************************\")\n",
    "    find_analogies('king', 'man', 'woman', We, word2idx, idx2word)\n",
    "    find_analogies('france', 'paris', 'london', We, word2idx, idx2word)\n",
    "    find_analogies('france', 'paris', 'rome', We, word2idx, idx2word)\n",
    "    find_analogies('paris', 'france', 'italy', We, word2idx, idx2word)\n",
    "    find_analogies('france', 'french', 'english', We, word2idx, idx2word)\n",
    "    find_analogies('japan', 'japanese', 'chinese', We, word2idx, idx2word)\n",
    "    find_analogies('japan', 'japanese', 'italian', We, word2idx, idx2word)\n",
    "    find_analogies('japan', 'japanese', 'australian', We, word2idx, idx2word)\n",
    "    find_analogies('december', 'november', 'june', We, word2idx, idx2word)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
